{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 import\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 오토인코더 모델 클래스 생성\n",
    "class Autoencoder(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Autoencoder, self).__init__()\n",
    "    # 인코더\n",
    "    self.encoder = nn.Sequential(\n",
    "      nn.Linear(28*28, 128),\n",
    "      nn.Tanh(),\n",
    "      nn.Linear(128, 64),\n",
    "      nn.Tanh(),\n",
    "      nn.Linear(64, 12),\n",
    "      nn.Tanh(),\n",
    "      nn.Linear(12,3) # latent space\n",
    "    )\n",
    "    # 디코더\n",
    "    self.decoder = nn.Sequential(\n",
    "      nn.Linear(3, 12),\n",
    "      nn.Tanh(),\n",
    "      nn.Linear(12, 64),\n",
    "      nn.Tanh(),\n",
    "      nn.Linear(64, 128),\n",
    "      nn.Tanh(),\n",
    "      nn.Linear(128, 28*28),\n",
    "      nn.Sigmoid()    # output 0~1\n",
    "    )\n",
    "  # 순전파\n",
    "  def forward(self, x):\n",
    "    x_encoded = self.encoder(x)\n",
    "    x = self.decoder(x_encoded)\n",
    "    return x, x_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터변환\n",
    "transform = transforms.Compose([\n",
    "  transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# 학습데이터 로드 Load the train dataset\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# 테스트 데이터 로드\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: ./data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "           )"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
